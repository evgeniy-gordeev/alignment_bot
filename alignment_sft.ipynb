{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f10a6612-d68f-465d-a0a8-f766301a604b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U git+https://github.com/huggingface/transformers.git\n",
    "# !pip install trl\n",
    "# !pip install git+https://github.com/huggingface/peft.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31986e5e-46a1-44bd-a0c5-59d55b46151a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.dataset as ds\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "from datasets import Dataset, load_dataset\n",
    "from peft import LoraConfig\n",
    "from trl import ModelConfig, SFTConfig, SFTTrainer\n",
    "from transformers import AutoModelForCausalLM, TrainingArguments\n",
    "\n",
    "wandb.finish()\n",
    "os.environ['WANDB_DISABLED'] = 'true'\n",
    "\n",
    "# dataset = load_dataset(\"imdb\", split=\"train\")\n",
    "\n",
    "# if torch.backends.mps.is_built():\n",
    "#     device = torch.device(\"mps\")\n",
    "\n",
    "model_name = 'AnatoliiPotapov/T-lite-instruct-0.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d53f6e5e-5ce7-4e08-aa78-3cfa06aa099c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a562ee3ac9494684a12e6d1be373c74b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "sft_config = TrainingArguments(output_dir='test_trainer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "855cf28d-df07-4e2f-af99-b699dbe0b9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Каковы текущие котировки акций компании Apple?\"}, {\"role\": \"bot\", \"content\": \"Текущие котировки акций Apple составляют $173.21.\"}]}\n",
    "]\n",
    "#     {\"role\": \"user\", \"content\": \"Каковы текущие котировки акций компании Apple?\"},\n",
    "#     {\"role\": \"bot\", \"content\": \"Текущие котировки акций Apple составляют $173.21.\"},\n",
    "    \n",
    "#     {\"role\": \"user\", \"content\": \"Какая доходность облигаций государственного займа США на сегодня?\"},\n",
    "#     {\"role\": \"bot\", \"content\": \"Доходность облигаций государственного займа США на сегодня составляет 2.75%.\"},\n",
    "    \n",
    "#     {\"role\": \"user\", \"content\": \"Расскажи о последних новостях на фондовом рынке.\"},\n",
    "#     {\"role\": \"bot\", \"content\": \"Сегодня на фондовом рынке наблюдается рост индексов S&P 500 и NASDAQ после позитивных экономических отчетов.\"},\n",
    "    \n",
    "#     {\"role\": \"user\", \"content\": \"Как изменился курс евро к доллару за последние неделю?\"},\n",
    "#     {\"role\": \"bot\", \"content\": \"Курс евро к доллару изменился с 1.092 до 1.095 за последнюю неделю.\"},\n",
    "    \n",
    "#     {\"role\": \"user\", \"content\": \"Какие акции показали наибольший рост в этом месяце?\"},\n",
    "#     {\"role\": \"bot\", \"content\": \"В этом месяце наибольший рост показали акции Tesla, выросшие на 15%.\"},\n",
    "    \n",
    "#     {\"role\": \"user\", \"content\": \"Какие компании выплатят дивиденды в этом квартале?\"},\n",
    "#     {\"role\": \"bot\", \"content\": \"В этом квартале дивиденды выплатят компании Microsoft, Johnson & Johnson и Coca-Cola.\"},\n",
    "    \n",
    "#     {\"role\": \"user\", \"content\": \"Каков прогноз по цене золота на следующий месяц?\"},\n",
    "#     {\"role\": \"bot\", \"content\": \"Прогноз по цене золота на следующий месяц предполагает её рост до $1,950 за унцию.\"},\n",
    "    \n",
    "#     {\"role\": \"user\", \"content\": \"Какие экономические отчеты ожидаются на этой неделе?\"},\n",
    "#     {\"role\": \"bot\", \"content\": \"На этой неделе ожидаются отчеты по безработице и ВВП США.\"},\n",
    "    \n",
    "#     {\"role\": \"user\", \"content\": \"Расскажи о финансовых результатах компании Microsoft за последний квартал.\"},\n",
    "#     {\"role\": \"bot\", \"content\": \"Компания Microsoft сообщила о доходах в размере $55.5 млрд и чистой прибыли $18.3 млрд за последний квартал.\"},\n",
    "    \n",
    "#     {\"role\": \"user\", \"content\": \"Как изменились ставки по ипотечным кредитам в этом месяце?\"},\n",
    "#     {\"role\": \"bot\", \"content\": \"Ставки по ипотечным кредитам в этом месяце снизились до 4.20%.\"},\n",
    "    \n",
    "#     {\"role\": \"user\", \"content\": \"Какие активы лучше всего инвестировать в условиях нестабильной экономики?\"},\n",
    "#     {\"role\": \"bot\", \"content\": \"В условиях нестабильной экономики рекомендуется инвестировать в золото, государственные облигации и диверсифицированные инвестиционные фонды.\"},\n",
    "    \n",
    "#     {\"role\": \"user\", \"content\": \"Что такое криптовалюта и как она работает?\"},\n",
    "#     {\"role\": \"bot\", \"content\": \"Криптовалюта — это цифровая валюта, использующая криптографию для обеспечения безопасности транзакций. Работает на основе блокчейн-технологии.\"},\n",
    "    \n",
    "#     {\"role\": \"user\", \"content\": \"Какие акции торгуются на Нью-Йоркской фондовой бирже?\"},\n",
    "#     {\"role\": \"bot\", \"content\": \"На Нью-Йоркской фондовой бирже торгуются такие акции, как IBM, Pfizer, Bank of America и многие другие.\"},\n",
    "    \n",
    "#     {\"role\": \"user\", \"content\": \"Какой прогноз по цене нефти на следующий квартал?\"},\n",
    "#     {\"role\": \"bot\", \"content\": \"Прогноз по цене нефти на следующий квартал предполагает её снижение до $70 за баррель.\"},\n",
    "    \n",
    "#     {\"role\": \"user\", \"content\": \"Какой текущий курс биткойна к доллару США?\"},\n",
    "#     {\"role\": \"bot\", \"content\": \"Текущий курс биткойна к доллару США составляет $27,500.\"},\n",
    "    \n",
    "#     {\"role\": \"user\", \"content\": \"Какие факторы влияют на изменение валютного курса?\"},\n",
    "#     {\"role\": \"bot\", \"content\": \"На изменение валютного курса влияют экономические показатели, политические события, рыночные ожидания и действия центральных банков.\"},\n",
    "    \n",
    "#     {\"role\": \"user\", \"content\": \"Какие инвестиции лучше всего подходят для пенсионного плана?\"},\n",
    "#     {\"role\": \"bot\", \"content\": \"Для пенсионного плана подойдут диверсифицированные инвестиционные фонды, облигации и высокодоходные акции компаний с долгой историей выплат дивидендов.\"},\n",
    "    \n",
    "#     {\"role\": \"user\", \"content\": \"Какие новости из Китая могут повлиять на мировую экономику?\"},\n",
    "#     {\"role\": \"bot\", \"content\": \"Новости из Китая, такие как изменения в экономической политике, данные по ВВП или торговые соглашения, могут значительно повлиять на мировую экономику.\"},\n",
    "    \n",
    "#     {\"role\": \"user\", \"content\": \"Каков текущий тренд на рынке недвижимости?\"},\n",
    "#     {\"role\": \"bot\", \"content\": \"Текущий тренд на рынке недвижимости показывает рост цен на жилье в крупных городах и замедление темпов роста в пригородах.\"},\n",
    "    \n",
    "#     {\"role\": \"user\", \"content\": \"Какие риски связаны с инвестированием в стартапы?\"},\n",
    "#     {\"role\": \"bot\", \"content\": \"Риски инвестирования в стартапы включают высокий уровень неопределенности, отсутствие доходов на начальных этапах и потенциальные проблемы с управлением компанией.\"},\n",
    "    \n",
    "#     {\"role\": \"user\", \"content\": \"Как выбрать хорошего финансового консультанта?\"},\n",
    "#     {\"role\": \"bot\", \"content\": \"Для выбора хорошего финансового консультанта важно учитывать его опыт, репутацию, уровень сертификации и подход к управлению инвестициями.\"},\n",
    "    \n",
    "#     {\"role\": \"user\", \"content\": \"Как изменяются фондовые индексы в зависимости от экономических условий?\"},\n",
    "#     {\"role\": \"bot\", \"content\": \"Фондовые индексы могут расти в условиях экономического роста и снижения, и наоборот, падать в условиях экономического спада.\"}\n",
    "# ]\n",
    "\n",
    "texts = [json.dumps(text) for text in texts]\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        'text': texts,\n",
    "        'label': [0 for _ in range(len(texts))]\n",
    "    }\n",
    ")\n",
    "dataset = ds.dataset(pa.Table.from_pandas(df).to_batches())\n",
    "\n",
    "hg_dataset = Dataset(pa.Table.from_pandas(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f38dce3-669f-4f0d-877d-d1d91a225188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{\"messages\": [{\"role\": \"user\", \"content\": \"\\\\u041a\\\\u0430\\\\u043a\\\\u043e\\\\u0432\\\\u044b \\\\u0442\\\\u0435\\\\u043a\\\\u0443\\\\u0449\\\\u0438\\\\u0435 \\\\u043a\\\\u043e\\\\u0442\\\\u0438\\\\u0440\\\\u043e\\\\u0432\\\\u043a\\\\u0438 \\\\u0430\\\\u043a\\\\u0446\\\\u0438\\\\u0439 \\\\u043a\\\\u043e\\\\u043c\\\\u043f\\\\u0430\\\\u043d\\\\u0438\\\\u0438 Apple?\"}, {\"role\": \"bot\", \"content\": \"\\\\u0422\\\\u0435\\\\u043a\\\\u0443\\\\u0449\\\\u0438\\\\u0435 \\\\u043a\\\\u043e\\\\u0442\\\\u0438\\\\u0440\\\\u043e\\\\u0432\\\\u043a\\\\u0438 \\\\u0430\\\\u043a\\\\u0446\\\\u0438\\\\u0439 Apple \\\\u0441\\\\u043e\\\\u0441\\\\u0442\\\\u0430\\\\u0432\\\\u043b\\\\u044f\\\\u044e\\\\u0442 $173.21.\"}]}']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hg_dataset['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f20528a-2ec8-4417-a731-b6f3ccd6f843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d6ee202428e4d0ba92113e8a1183d20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.96 GiB. GPU 2 has a total capacity of 31.73 GiB of which 1.12 GiB is free. Process 63451 has 374.00 MiB memory in use. Including non-PyTorch memory, this process has 30.24 GiB memory in use. Of the allocated memory 29.94 GiB is allocated by PyTorch, and 4.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\u001b[39;00m\n\u001b[1;32m     14\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:2\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m sft_config \u001b[38;5;241m=\u001b[39m TrainingArguments(output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_trainer\u001b[39m\u001b[38;5;124m'\u001b[39m, use_cpu\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# model = AutoModelForCausalLM.from_pretrained(model_config.model_name_or_path)#.to(device)\u001b[39;00m\n",
      "File \u001b[0;32m~/environments/hack/lib/python3.10/site-packages/transformers/modeling_utils.py:2920\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2915\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[1;32m   2916\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2917\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2918\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2919\u001b[0m         )\n\u001b[0;32m-> 2920\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/environments/hack/lib/python3.10/site-packages/torch/nn/modules/module.py:1174\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1171\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1172\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/environments/hack/lib/python3.10/site-packages/torch/nn/modules/module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/environments/hack/lib/python3.10/site-packages/torch/nn/modules/module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/environments/hack/lib/python3.10/site-packages/torch/nn/modules/module.py:805\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 805\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    806\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    808\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/environments/hack/lib/python3.10/site-packages/torch/nn/modules/module.py:1160\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1154\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1155\u001b[0m             device,\n\u001b[1;32m   1156\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m             non_blocking,\n\u001b[1;32m   1158\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1159\u001b[0m         )\n\u001b[0;32m-> 1160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.96 GiB. GPU 2 has a total capacity of 31.73 GiB of which 1.12 GiB is free. Process 63451 has 374.00 MiB memory in use. Including non-PyTorch memory, this process has 30.24 GiB memory in use. Of the allocated memory 29.94 GiB is allocated by PyTorch, and 4.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# sft_config = TrainingArguments(\n",
    "#     output_dir='test_trainer',\n",
    "#     per_gpu_train_batch_size=4,\n",
    "# )\n",
    "\n",
    "\n",
    "model_config = ModelConfig(\n",
    "    model_name_or_path=model_name,\n",
    "    attn_implementation='flash_attention_2'\n",
    ")\n",
    "# device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
    "sft_config = TrainingArguments(output_dir='test_trainer', use_cpu=True)\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_config.model_name_or_path)#.to(device)\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model,\n",
    "    train_dataset=hg_dataset,\n",
    "    # args=sft_config,\n",
    "    dataset_text_field=\"text\",\n",
    "    packing=False,\n",
    "    # peft_config=peft_config,\n",
    "    max_seq_length=256\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7ae490-eb09-4cc3-b68a-8a435db576e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.dataset as ds\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig\n",
    "from trl import ModelConfig, SFTConfig, SFTTrainer\n",
    "from transformers import AutoModelForCausalLM, TrainingArguments\n",
    "\n",
    "wandb.finish()\n",
    "os.environ['WANDB_DISABLED'] = 'true'\n",
    "\n",
    "MODEL_NAME = 'AnatoliiPotapov/T-lite-instruct-0.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250ef1a0-6555-43fd-a118-99551c6a6db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": \"Каковы текущие котировки акций компании Apple?\"},\n",
    "            {\"role\": \"bot\", \"content\": \"Текущие котировки акций Apple составляют $173.21.\"},\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": \"Какие экономические отчеты ожидаются на этой неделе?\"},\n",
    "            {\"role\": \"bot\", \"content\": \"На этой неделе ожидаются отчеты по безработице и ВВП США.\"},\n",
    "        ]\n",
    "    },\n",
    "]\n",
    "\n",
    "texts = [json.dumps(text) for text in texts]\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        'text': texts,\n",
    "        'label': [0 for _ in range(len(texts))]\n",
    "    }\n",
    ")\n",
    "dataset = ds.dataset(pa.Table.from_pandas(df).to_batches())\n",
    "\n",
    "hg_dataset = Dataset(pa.Table.from_pandas(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862e6063-4856-491e-8ff9-bedcf80dafa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = ModelConfig(\n",
    "    model_name_or_path=MODEL_NAME,\n",
    "    attn_implementation='flash_attention_2'\n",
    ")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "sft_config = TrainingArguments(output_dir='test_trainer', use_cpu=True,)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME).to(device)\n",
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias='none',\n",
    "    task_type='CAUSAL_LM',\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model,\n",
    "    train_dataset=hg_dataset,\n",
    "    args=sft_config,\n",
    "    dataset_text_field='text',\n",
    "    packing=False,\n",
    "    peft_config=peft_config,\n",
    "    max_seq_length=256\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96d8c90d-42d2-4e7f-8d22-3ddc4efe6453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2df9f9ad0ef942eeaf757ac5ee3e0159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d29f7145edc5429d83f11bef6d535894",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['{\"messages\": [{\"role\": \"user\", \"content\": \"\\\\u041a\\\\u0430\\\\u043a\\\\u043e\\\\u0432\\\\u044b \\\\u0442\\\\u0435\\\\u043a\\\\u0443\\\\u0449\\\\u0438\\\\u0435 \\\\u043a\\\\u043e\\\\u0442\\\\u0438\\\\u0440\\\\u043e\\\\u0432\\\\u043a\\\\u0438 \\\\u0430\\\\u043a\\\\u0446\\\\u0438\\\\u0439 \\\\u043a\\\\u043e\\\\u043c\\\\u043f\\\\u0430\\\\u043d\\\\u0438\\\\u0438 Apple?\"}]}? Работает на основе блокччифицированных транзакций. Работает на основе криптовалюта. Работает на основе блокччифицированных транзакций. Работает на основе блокччифицированных транзакций. Работает на основе блокччифицированных транзакций. Работает на основе блокччифицированных транзакций. Работает на основе блокччифицированных транзакций. Работает на основе блокччифицированных транзакций. Работает на основе блокччифицированных транзакций. Работает на основе блокччифицированных транзакций. Работает на основе блокччифицированных транзакций. Работает на основе блокччифицированных транзакций. Работает на основе блокччифицированных транзакций. Работает на основе блокччифицированных транзакций. Работает на основе блокччифицированных транзакций. Работает на основе блокччифицированных транзакций. Работает на основе блок']\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import json\n",
    "import torch\n",
    "\n",
    "model_name = 'test_trainer/align-checkpoint-18'\n",
    "device = \"cpu\" if torch.cuda.is_available() else \"cpu\"\n",
    "questions = [{\"messages\": [{\"role\": \"user\", \"content\": \"Каковы текущие котировки акций компании Apple?\"}]}]\n",
    "questions = [json.dumps(question) for question in questions]\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "inputs = tokenizer(questions, return_tensors=\"pt\",).to(device)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
    "assistant_model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
    "outputs = model.generate(**inputs, prompt_lookup_num_tokens=9, use_cache=True, max_new_tokens=300)\n",
    "print(tokenizer.batch_decode(outputs, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "92916f66-1077-4728-9a7b-4cd4d62994ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " alignment_sft.ipynb   lib\t      turbo_allignment-Copy1.ipynb\n",
      " bin\t\t       lib64\t      turbo_allignment.ipynb\n",
      " chatgpt.json\t       pyvenv.cfg    'Без названия.ipynb'\n",
      " etc\t\t       share\t     'Без названия1.ipynb'\n",
      " include\t       test_trainer  'Без названия2.ipynb'\n"
     ]
    }
   ],
   "source": [
    "!ls test_trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8c98fde7-cd2f-4a24-a861-1430f5e49687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пожалуйста, не надо грубости)))\n",
      "Изивините, мне нужно подумать еще чуть-чуть над вопросом, задайте, пожлуйста его попозже\n",
      "Изивините, мне нужно подумать еще чуть-чуть над вопросом, задайте, пожлуйста его попозже\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "INPOLITE_QUESTION_REPLY = 'Пожалуйста, не надо грубости)))'\n",
    "INPOLITE_REPLY_DETECTED = 'Изивините, мне нужно подумать еще чуть-чуть над вопросом, задайте, пожлуйста его попозже'\n",
    "REGEX = [\n",
    "    re.compile(r'(\\W+|^)бл(я)+(\\W+|$)', flags=re.IGNORECASE),\n",
    "    re.compile(r'(\\W+|^)бля(дт)(и|ь)(\\W+|$)', flags=re.IGNORECASE),\n",
    "    re.compile(r'(\\W+|^)мраз(и|ь)(\\W+|$)', flags=re.IGNORECASE),\n",
    "    re.compile(r'(\\W+|^)с(у)+к(а|и)+(\\W+|$)', flags=re.IGNORECASE),\n",
    "    re.compile(r'(\\W+|^)г(а|о)вно(\\W+|$)', flags=re.IGNORECASE),\n",
    "    re.compile(r'(\\W+|^)дерьмо(\\W+|$)', flags=re.IGNORECASE),\n",
    "]\n",
    "\n",
    "\n",
    "def regex_check(text: str) -> bool:\n",
    "    for regex in REGEX:\n",
    "        if len(re.findall(regex, text)):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "texts = ['asdf', 'Бляяяя', 'Смущают меня эти сукачи', 'Ну ты конечно и сука', 'сука',]\n",
    "questions = ['asdf', 'Бляяяя',]\n",
    "answers = ['Смущают меня эти сукачи', 'Ну ты конечно и сука', 'сука',]\n",
    "\n",
    "for text in texts:\n",
    "    if text in questions and regex_check(text):\n",
    "        print(INPOLITE_QUESTION_REPLY)\n",
    "    if text in answers and regex_check(text):\n",
    "        print(INPOLITE_REPLY_DETECTED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "113bcec4-0a16-4ac7-822d-13c795af1253",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'regex' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mregex\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'regex' is not defined"
     ]
    }
   ],
   "source": [
    "regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e608322b-b206-45d8-915e-12687dfb7f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
